{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37864bittfmainvenvd98ddf667aad420d8b18f6282cda8b05",
   "display_name": "Python 3.7.8 64-bit ('tf_main': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_names = ['acc_x', 'acc_y', 'acc_z', 'acc_xg', 'acc_yg', 'acc_zg', 'acc', 'acc_g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_features(data):\n",
    "    data.drop(columns=['time_point'], inplace=True)\n",
    "\n",
    "    data['acc'] = (data.acc_x ** 2 + data.acc_y ** 2 + data.acc_z ** 2) ** 0.5\n",
    "    data['acc_g'] = (data.acc_xg ** 2 + data.acc_yg ** 2 + data.acc_zg ** 2) ** 0.5\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传统padding\n",
    "def handle_mats(grouped_data):\n",
    "    mats = [i.values for i in grouped_data]\n",
    "    max_len = 60\n",
    "    for i in range(len(mats)):\n",
    "        if len(mats[i]) < max_len:\n",
    "            padding_size = max_len - len(mats[i])\n",
    "            mats[i] = np.r_[mats[i], np.zeros([padding_size, mats[i].shape[-1]])]\n",
    "        else:\n",
    "            mats[i] = mats[i][:max_len]\n",
    "        mats[i] = mats[i][np.newaxis, :, :]\n",
    "\n",
    "    return np.concatenate(mats, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_train = pd.read_csv('../dataset/sensor_train_final.csv')\n",
    "sensor_test = pd.read_csv('../dataset/sensor_test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = handle_features(sensor_train)\n",
    "test_data = handle_features(sensor_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data[src_names] = scaler.fit_transform(train_data[src_names])\n",
    "test_data[src_names] = scaler.transform(test_data[src_names])\n",
    "\n",
    "train_data_grouped = [i.drop(columns='fragment_id') for _, i in train_data.groupby('fragment_id')]\n",
    "train_labels = np.array([int(i.iloc[0]['behavior_id']) for i in train_data_grouped])\n",
    "test_data_grouped = [i.drop(columns='fragment_id') for _, i in test_data.groupby('fragment_id')]\n",
    "\n",
    "for i in range(len(train_data_grouped)):\n",
    "    train_data_grouped[i].drop(columns='behavior_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = handle_mats(train_data_grouped)\n",
    "test_data = handle_mats(test_data_grouped)\n",
    "\n",
    "train_data.shape, train_labels.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_length_data(data_grouped):\n",
    "    cnt = []\n",
    "    for i in range(len(data_grouped)):\n",
    "        cnt.append(len(data_grouped[i]))\n",
    "    return np.array(cnt)\n",
    "\n",
    "train_length_data = get_length_data(train_data_grouped)\n",
    "test_length_data = get_length_data(test_data_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('data',\n",
    "                    train_data=train_data,\n",
    "                    test_data=test_data,\n",
    "                    train_labels=train_labels,\n",
    "                    train_length_data=train_length_data,\n",
    "                    test_length_data=test_length_data\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}